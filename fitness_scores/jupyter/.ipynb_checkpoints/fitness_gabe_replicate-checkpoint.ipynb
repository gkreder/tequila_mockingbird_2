{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "\n",
    "REPLICATE = 'r1'\n",
    "# import fastq scrape\n",
    "\n",
    "time_points = [\n",
    "    't0_r1',\n",
    "    't1_r1',\n",
    "    't2_r1',\n",
    "    't0_r2',\n",
    "    't1_r2',\n",
    "    't2_r2',\n",
    "    't0_control',\n",
    "    't1_control',\n",
    "    't2_control']\n",
    "\n",
    "ID_timepoint_dict = {\n",
    "    'ATTCCG' : 't0_control',\n",
    "    'AGCTAG' : 't1_control',\n",
    "    'GTATAG' : 't2_control',\n",
    "    'ATCAGT' : 't0_r1',\n",
    "    'GCTCAT' : 't1_r1',\n",
    "    'AGGAAT' : 't2_r1',\n",
    "    'CTTTTG' : 't0_r2',\n",
    "    'TAGTTG' : 't1_r2',\n",
    "    'CCGGTG' : 't2_r2'\n",
    "}\n",
    "\n",
    "timepoint_generation_dict = {'t0_r1' : 0.0,\n",
    "                             't1_r1' : 1.91,\n",
    "                             't2_r1': 3.328354364,\n",
    "                             't0_r2' : 0.0,\n",
    "                             't1_r2' : 1.35,\n",
    "                             't2_r2' : 2.96,\n",
    "                             't0_control' : 0.0,\n",
    "                             't1_control' : 2.022367813,\n",
    "                             't2_control' : 3.50041511\n",
    "                            }\n",
    "\n",
    "\n",
    "allele_data = pickle.load(open('allele_dic_with_WT.pkl', 'rb'))\n",
    "aminotonumber_data = pickle.load(open('aminotonumber.pkl', 'rb'))\n",
    "translate_data_RNA = pickle.load(open('translate.pkl', 'rb'))\n",
    "translate_data_DNA = {}\n",
    "for codon in translate_data_RNA:\n",
    "    translate_data_DNA[codon.replace('U', 'T')] = translate_data_RNA[codon]\n",
    "translate_data_DNA['WT'] = 'WT'\n",
    "\n",
    "def compare_string_lists(l1, l2):\n",
    "#     print(l1, l2)\n",
    "    for index, element in enumerate(l1):\n",
    "        if len(l1) != len(l2):\n",
    "            return False\n",
    "        if element != l2[index]:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \n",
    "# Initial Data Scrape from Fastq files\n",
    "# \n",
    "df = pd.DataFrame()\n",
    "ID = []\n",
    "read = []\n",
    "quality_score = []\n",
    "barcodes = []\n",
    "codon = []\n",
    "loc = []\n",
    "time_point_tag = []\n",
    "\n",
    "\n",
    "def get_filename(time_point):\n",
    "    filename_short = '../../' + time_point + '_short.fastq'\n",
    "    return filename_short\n",
    "#     filename_long = '../../' + time_point + '_index.fastq'\n",
    "#     return filename_long\n",
    "\n",
    "for time_point in [t for t in time_points if REPLICATE in t]\n",
    "    print(time_point)\n",
    "    filename = get_filename(time_point)\n",
    "    file = open(filename)\n",
    "    for line_number, line in enumerate(file):\n",
    "        if line_number % 4 == 0:\n",
    "            ID.append(line.strip().split(':')[-1])\n",
    "        elif line_number % 4 == 1:\n",
    "            read.append(line.strip())\n",
    "            barcode = line.strip()[0:18]\n",
    "            barcodes.append(barcode)\n",
    "            barcode_lookup = str(Seq(barcode).reverse_complement())\n",
    "            if barcode_lookup in allele_data:\n",
    "                codon.append(allele_data[barcode_lookup][1])\n",
    "                loc.append(allele_data[barcode_lookup][0])\n",
    "            else:\n",
    "                codon.append('NONE')\n",
    "                loc.append('NONE')\n",
    "\n",
    "        elif line_number % 4 == 3:\n",
    "            quality_score.append(line.strip())\n",
    "            time_point_tag.append(time_point)\n",
    "df['ID'] = ID\n",
    "df['read'] = read\n",
    "df['time_point'] = time_point_tag\n",
    "df['codon'] = codon\n",
    "df['loc'] = loc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \n",
    "# Get normalized barcode counts per timestep and label with generation, timepoint, and replicate\n",
    "# \n",
    "\n",
    "df_in_dict = df[~(df['codon'] == 'NONE')].copy()\n",
    "# df_in_dict.groupby('time_point').codon.nunique()\n",
    "grouped_counts = df_in_dict.groupby('time_point').read.value_counts(normalize = True)\n",
    "keys = grouped_counts.keys()\n",
    "def label_row_counts(row):\n",
    "    temp_key = (row['time_point'], row['read'])\n",
    "    for key in keys:\n",
    "        if temp_key == key:\n",
    "            return grouped_counts[key]\n",
    "    return 'NO COUNT FOUND'\n",
    "\n",
    "def label_row_generations(row):\n",
    "    return timepoint_generation_dict[row['time_point']]\n",
    "\n",
    "def label_row_replicate(row):\n",
    "    return row['time_point'].split('_')[1]\n",
    "def label_row_time(row):\n",
    "    return row['time_point'].split('_')[0]\n",
    "\n",
    "df_in_dict['count'] = df_in_dict.apply(lambda row: label_row_counts(row), axis=1)\n",
    "AA_list = [translate_data_DNA[codon] for codon in df_in_dict['codon'].values.tolist()]\n",
    "df_in_dict['AA'] = AA_list\n",
    "# df_in_dict[df_in_dict['time_point'] == 't2_r2']\n",
    "df_total = df_in_dict.copy()\n",
    "df_total['generation'] = df_total.apply(lambda row: label_row_generations(row), axis=1)\n",
    "df_total['time'] = df_total.apply(lambda row: label_row_time(row), axis=1)\n",
    "df_total['replicate'] = df_total.apply(lambda row: label_row_replicate(row), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \n",
    "# Calculate Slopes (can change our filtering of slope values here)\n",
    "# \n",
    "df_slopes = df_total.drop_duplicates().copy()\n",
    "barcode_groups = df_slopes.groupby(['read', 'replicate'])\n",
    "groups = barcode_groups.groups\n",
    "for group in barcode_groups.groups:\n",
    "    replicate = group[1]\n",
    "    temp_group = barcode_groups.get_group(group)\n",
    "    temp_x = temp_group['generation'].values\n",
    "    temp_y = temp_group['count'].values\n",
    "    timepoints_present = temp_group['time'].values\n",
    "    if compare_string_lists(timepoints_present, ['t1','t2']):\n",
    "        temp_x = [0.0] + temp_x\n",
    "        temp_y = [0.0] + temp_y\n",
    "    elif compare_string_lists(timepoints_present, ['t0']):\n",
    "        generation_1 = timepoint_generation_dict['t1_' + replicate]\n",
    "        generation_2 = timepoint_generation_dict['t2_' + replicate]\n",
    "        temp_x = temp_x + [generation_1, generation_2]\n",
    "        temp_y = temp_y + [0.0, 0.0]\n",
    "    slope, intercept, r_value, p_value, std_err = scipy.stats.linregress(temp_x,temp_y)\n",
    "    indices_temp = temp_group.index.values\n",
    "    for index in indices_temp:\n",
    "        df_slopes.set_value(index, 'slope', slope)\n",
    "        df_slopes.set_value(index, 'std_err', std_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# \n",
    "# Calculate the average slope values\n",
    "# \n",
    "df_barcode_scores = df_slopes.drop_duplicates(subset = ['read', 'replicate']).copy()\n",
    "df_AA_avg = pd.DataFrame(df_barcode_scores.groupby(['loc', 'AA', 'replicate']).mean().copy())\n",
    "pickle.dump(df_AA_avg, open('df_AA_avg.pkl', 'wb'))\n",
    "\n",
    "# keys_temp = df_AA_avg['slope'].keys()\n",
    "# for key in keys_temp:\n",
    "#     print(key)\n",
    "\n",
    "\n",
    "# \n",
    "# Separate out into replicate DFs\n",
    "# \n",
    "def subtract_wildtype(df_replicate):\n",
    "    WT_slope = df_replicate[df_replicate['AA'] == 'WT']['slope']\n",
    "    normalized_slopes = df_replicate.apply(lambda row : row['slope'] - WT_slope, axis = 1)\n",
    "    df_replicate['slope_normalized'] = normalized_slopes\n",
    "    df_return = df_replicate.copy()\n",
    "    return df_return\n",
    "\n",
    "df_r1 = df_AA_avg.reset_index().copy()\n",
    "df_r1 = pd.DataFrame(df_r1[df_r1['replicate'] == 'r1'])\n",
    "df_r1 = subtract_wildtype(df_r1)\n",
    "pickle.dump(df_r1, open('df_r1.pkl', 'wb'))\n",
    "\n",
    "df_r2 = df_AA_avg.reset_index().copy()\n",
    "df_r2 = pd.DataFrame(df_r2[df_r2['replicate'] == 'r2'])\n",
    "df_r2 = subtract_wildtype(df_r2)\n",
    "pickle.dump(df_r2, open('df_r2.pkl', 'wb'))\n",
    "\n",
    "df_control = df_AA_avg.reset_index().copy()\n",
    "df_control = pd.DataFrame(df_control[df_control['replicate'] == 'control'])\n",
    "df_control = subtract_wildtype(df_control)\n",
    "pickle.dump(df_control, open('df_control.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_df_replicate(df, filename, normalized = True):\n",
    "    df_working = df.copy()\n",
    "    df_working = df_working.drop('std_err', 1)\n",
    "    df_working = df_working.drop('count', 1)\n",
    "    df_working = df_working.drop('generation', 1)\n",
    "    df_working = df_working.drop('replicate', 1)\n",
    "    if normalized:\n",
    "        df_working = df_working.drop('slope', 1)\n",
    "        df_working = df_working.pivot(index='AA', columns='loc', values='slope_normalized')\n",
    "    else:\n",
    "        df_working = df_working.drop('slope_normalized', 1)\n",
    "        df_working = df_working.pivot(index='AA', columns='loc', values='slope')\n",
    "    pickle.dump(df_working, open(filename, 'wb'))\n",
    "#     sns.heatmap(df_working)\n",
    "#     plt.show()\n",
    "\n",
    "plot_df_replicate(df_control, 'control_heat_df.pkl')\n",
    "plot_df_replicate(df_r1, 'r1_heat_df.pkl')\n",
    "plot_df_replicate(df_r2, 'r2_heat_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
